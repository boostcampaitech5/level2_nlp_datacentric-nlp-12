{
 "cells": [
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Cleanlab 라이브러리를 사용한 라벨 오류 제거"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import random\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "\n",
    "import torch\n",
    "from torch.utils.data import Dataset\n",
    "from transformers import AutoModelForSequenceClassification\n",
    "\n",
    "from tokenization_kobert import KoBertTokenizer\n",
    "\n",
    "SEED = 456\n",
    "random.seed(SEED)\n",
    "np.random.seed(SEED)\n",
    "torch.manual_seed(SEED)\n",
    "torch.cuda.manual_seed(SEED)\n",
    "torch.cuda.manual_seed_all(SEED)\n",
    "pd.set_option(\"display.max_colwidth\", None)\n",
    "\n",
    "import re \n",
    "import pandas as pd \n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sentence_transformers import SentenceTransformer\n",
    "\n",
    "from cleanlab.classification import CleanLearning\n",
    "\n",
    "DEVICE = torch.device('cuda') if torch.cuda.is_available() else torch.device('cpu')\n",
    "\n",
    "BASE_DIR = os.getcwd()\n",
    "DATA_DIR = os.path.join(BASE_DIR, '../data')\n",
    "OUTPUT_DIR = os.path.join(BASE_DIR, '../output')\n",
    "\n",
    "dataset_train = pd.read_csv(os.path.join(DATA_DIR, 'train_crawl.csv'))\n",
    "dataset_valid = pd.read_csv(os.path.join(DATA_DIR, 'dev_crawl.csv'))\n",
    "\n",
    "# input 데이터\n",
    "raw_train_texts = dataset_train['text'].values\n",
    "raw_valid_texts = dataset_valid['text'].values\n",
    "\n",
    "# label 데이터\n",
    "train_labels = dataset_train['target'].values\n",
    "valid_labels = dataset_valid['target'].values"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## klue 버전 cleanlab - ai-hub 데이터"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sentence_transformers import SentenceTransformer, models\n",
    "from transformers import AutoTokenizer, AutoModel\n",
    "full_hub = pd.read_csv('../notebooks/full_hub_data.csv')\n",
    "\n",
    "MODEL_NAME = \"klue/roberta-large\"\n",
    "# Use HuggingFace/Transformers model\n",
    "tokenizer = AutoTokenizer.from_pretrained(MODEL_NAME)\n",
    "bert_model = AutoModel.from_pretrained(MODEL_NAME)\n",
    "\n",
    "# Use BERT for mapping tokens to embeddings\n",
    "word_embedding_model = models.Transformer(MODEL_NAME)\n",
    "\n",
    "# Apply mean pooling to get one fixed sized sentence vector\n",
    "pooling_model = models.Pooling(bert_model.config.hidden_size)\n",
    "\n",
    "model = SentenceTransformer(modules=[word_embedding_model, pooling_model])\n",
    "\n",
    "train_texts = model.encode(full_hub['text'].values)\n",
    "train_labels = full_hub['target'].values\n",
    "\n",
    "# calculate label error rate, cleansing error label depends on cutoff\n",
    "def label_cleaning(source_df: pd.DataFrame, data: np.ndarray, labels: np.ndarray) -> pd.DataFrame:\n",
    "    \"\"\"\n",
    "    Cleanlab 라이브러리를 활용해 잘못 라벨링이 되어있는 경우를 예측해 0과 1사이의 labe_quality와 예상되는 정답라벨을 출력\n",
    "    이를 원본 데이터의 컬럼으로 추가해서 반환\n",
    "\n",
    "    Args:\n",
    "        source_df: 원본 데이터가 있는 DataFrame\n",
    "        data: 로지스틱 회귀 모델에 공급될 특성 값을 가진 데이터 배열\n",
    "        labels: 데이터와 연관된 원래 레이블의 배열\n",
    "    \n",
    "    Returns:\n",
    "        df: 원본 데이터와 label_quality, predicted_label을 붙인 결과\n",
    "\n",
    "    \"\"\"\n",
    "    model = LogisticRegression(max_iter=500)\n",
    "    cv_n_folds = 5  \n",
    "    cl = CleanLearning(model, cv_n_folds=cv_n_folds)\n",
    "\n",
    "    label_issues_df = cl.find_label_issues(X=data, labels=labels)\n",
    "\n",
    "    label_issues_df = label_issues_df[['label_quality', 'predicted_label']]\n",
    "    source_df.reset_index(drop=True, inplace=True)\n",
    "\n",
    "    df = pd.concat([source_df, label_issues_df], axis=1)\n",
    "\n",
    "    return df\n",
    "\n",
    "df_hub = label_cleaning(full_hub, train_texts, train_labels)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = df_hub.copy()\n",
    "\n",
    "dictionary = {\n",
    "    0: 'IT과학',\n",
    "    1: '경제',\n",
    "    2: '사회',\n",
    "    3: '문화',\n",
    "    4: '국제',\n",
    "    5: '스포츠',\n",
    "    6: '정치'\n",
    "}\n",
    "\n",
    "df['text_target'] = df['target'].replace(dictionary)\n",
    "df['text_predicted_label'] = df['predicted_label'].replace(dictionary)\n",
    "df.drop(['publish_date', 'year', 'len'], axis=1, inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 82,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>text</th>\n",
       "      <th>target</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>104453</th>\n",
       "      <td>광주시, 국가 인공지능 데이터센터 서비스 이용자 모집</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>105292</th>\n",
       "      <td>광주시, 인공지능·양자산업 육성</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>107684</th>\n",
       "      <td>2023년 빅데이터·AI 활용 '똑똑한 발전소' 나온다</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>21558</th>\n",
       "      <td>부산시, 인공지능(AI) 기반 실시간 게임 분석기술 개발 추진</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>25912</th>\n",
       "      <td>부산시, 인공지능 기반 실시간 게임 분석기술 개발</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>30476</th>\n",
       "      <td>신영대 의원, 민주당 대선경선기획단에 인선</td>\n",
       "      <td>6</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13018</th>\n",
       "      <td>\"친애하는 정성호 동지\"란 추미애…野 \"소음에 온 국민 피곤\"</td>\n",
       "      <td>6</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>377</th>\n",
       "      <td>여야 후보들 레이스 본격화… 박-우, 나-오 ‘토론 맞대결’ 하이라이트</td>\n",
       "      <td>6</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>45005</th>\n",
       "      <td>'풍요속 불안', 국민의힘 서울시장 주자 10명...안 대표와 단일화 '관심'</td>\n",
       "      <td>6</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>94046</th>\n",
       "      <td>사실상 당론? 김태년 \"임성근 탄핵 표결로 헌법 책임 다하겠다\"</td>\n",
       "      <td>6</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>9000 rows × 2 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                                               text target\n",
       "104453                광주시, 국가 인공지능 데이터센터 서비스 이용자 모집      0\n",
       "105292                            광주시, 인공지능·양자산업 육성      0\n",
       "107684               2023년 빅데이터·AI 활용 '똑똑한 발전소' 나온다      0\n",
       "21558            부산시, 인공지능(AI) 기반 실시간 게임 분석기술 개발 추진      0\n",
       "25912                   부산시, 인공지능 기반 실시간 게임 분석기술 개발      0\n",
       "...                                             ...    ...\n",
       "30476                       신영대 의원, 민주당 대선경선기획단에 인선      6\n",
       "13018            \"친애하는 정성호 동지\"란 추미애…野 \"소음에 온 국민 피곤\"      6\n",
       "377         여야 후보들 레이스 본격화… 박-우, 나-오 ‘토론 맞대결’ 하이라이트      6\n",
       "45005   '풍요속 불안', 국민의힘 서울시장 주자 10명...안 대표와 단일화 '관심'      6\n",
       "94046           사실상 당론? 김태년 \"임성근 탄핵 표결로 헌법 책임 다하겠다\"      6\n",
       "\n",
       "[9000 rows x 2 columns]"
      ]
     },
     "execution_count": 82,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "label_nums = [1500, 1500, 1500, 1500, 1000, 1000, 1000]\n",
    "\n",
    "final_df = pd.DataFrame(columns=df.columns)\n",
    "for i in range(7):\n",
    "    new_df = df[df['target'] == i].sort_values('label_quality', ascending=False)[:label_nums[i]]\n",
    "    final_df = pd.concat([final_df, new_df])\n",
    "final_df = final_df[['text', 'target']]\n",
    "final_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 83,
   "metadata": {},
   "outputs": [],
   "source": [
    "# final_df.to_csv('../hub_cleanlab_data.csv', index=False)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## klue 버전 cleanlab - train, valid"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "No sentence-transformers model found with name /opt/ml/.cache/torch/sentence_transformers/klue_roberta-large. Creating a new one with MEAN pooling.\n",
      "Some weights of the model checkpoint at /opt/ml/.cache/torch/sentence_transformers/klue_roberta-large were not used when initializing RobertaModel: ['lm_head.dense.bias', 'lm_head.decoder.bias', 'lm_head.dense.weight', 'lm_head.layer_norm.bias', 'lm_head.layer_norm.weight', 'lm_head.decoder.weight', 'lm_head.bias']\n",
      "- This IS expected if you are initializing RobertaModel from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).\n",
      "- This IS NOT expected if you are initializing RobertaModel from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).\n",
      "Some weights of RobertaModel were not initialized from the model checkpoint at /opt/ml/.cache/torch/sentence_transformers/klue_roberta-large and are newly initialized: ['roberta.pooler.dense.bias', 'roberta.pooler.dense.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
      "/opt/conda/lib/python3.8/site-packages/sklearn/linear_model/_logistic.py:458: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n",
      "/opt/conda/lib/python3.8/site-packages/sklearn/linear_model/_logistic.py:458: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n",
      "/opt/conda/lib/python3.8/site-packages/sklearn/linear_model/_logistic.py:458: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n",
      "/opt/conda/lib/python3.8/site-packages/sklearn/linear_model/_logistic.py:458: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n",
      "/opt/conda/lib/python3.8/site-packages/sklearn/linear_model/_logistic.py:458: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
      "To disable this warning, you can either:\n",
      "\t- Avoid using `tokenizers` before the fork if possible\n",
      "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n",
      "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
      "To disable this warning, you can either:\n",
      "\t- Avoid using `tokenizers` before the fork if possible\n",
      "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n",
      "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
      "To disable this warning, you can either:\n",
      "\t- Avoid using `tokenizers` before the fork if possible\n",
      "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n",
      "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
      "To disable this warning, you can either:\n",
      "\t- Avoid using `tokenizers` before the fork if possible\n",
      "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n",
      "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
      "To disable this warning, you can either:\n",
      "\t- Avoid using `tokenizers` before the fork if possible\n",
      "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n",
      "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
      "To disable this warning, you can either:\n",
      "\t- Avoid using `tokenizers` before the fork if possible\n",
      "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n",
      "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
      "To disable this warning, you can either:\n",
      "\t- Avoid using `tokenizers` before the fork if possible\n",
      "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n",
      "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
      "To disable this warning, you can either:\n",
      "\t- Avoid using `tokenizers` before the fork if possible\n",
      "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n",
      "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
      "To disable this warning, you can either:\n",
      "\t- Avoid using `tokenizers` before the fork if possible\n",
      "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n"
     ]
    }
   ],
   "source": [
    "from sentence_transformers import SentenceTransformer, models\n",
    "from transformers import AutoTokenizer, AutoModel\n",
    "train = pd.read_csv('../data/train.csv')\n",
    "\n",
    "raw_train_texts = train['text'].values\n",
    "train_labels = train['target'].values\n",
    "\n",
    "MODEL_NAME = \"klue/roberta-large\"\n",
    "model = SentenceTransformer(MODEL_NAME)\n",
    "\n",
    "# Get the sentence embeddings\n",
    "train_texts = model.encode(raw_train_texts)\n",
    "\n",
    "df_train = label_cleaning(train, train_texts, train_labels)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 원래 나뉘어져 있던 것을 가져와서 각각 clean 하는 과정\n",
    "from sentence_transformers import SentenceTransformer, models\n",
    "from transformers import AutoTokenizer, AutoModel\n",
    "\n",
    "MODEL_NAME = \"klue/roberta-large\"\n",
    "# Use HuggingFace/Transformers model\n",
    "tokenizer = AutoTokenizer.from_pretrained(MODEL_NAME)\n",
    "bert_model = AutoModel.from_pretrained(MODEL_NAME)\n",
    "\n",
    "# Use BERT for mapping tokens to embeddings\n",
    "word_embedding_model = models.Transformer(MODEL_NAME)\n",
    "\n",
    "# Apply mean pooling to get one fixed sized sentence vector\n",
    "pooling_model = models.Pooling(bert_model.config.hidden_size)\n",
    "\n",
    "model = SentenceTransformer(modules=[word_embedding_model, pooling_model])\n",
    "\n",
    "# Get the sentence embeddings\n",
    "train_texts = model.encode(raw_train_texts)\n",
    "valid_texts = model.encode(raw_valid_texts)\n",
    "\n",
    "df_train = label_cleaning(dataset_train, train_texts, train_labels)\n",
    "df_valid = label_cleaning(dataset_valid, valid_texts, valid_labels)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>ID</th>\n",
       "      <th>text</th>\n",
       "      <th>target</th>\n",
       "      <th>label_quality</th>\n",
       "      <th>predicted_label</th>\n",
       "      <th>text_target</th>\n",
       "      <th>text_predicted_label</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>5480</th>\n",
       "      <td>ynat-v1_train_05480</td>\n",
       "      <td>KT·SKT 5G 통신 국제 표준 규격 개발 주도종합</td>\n",
       "      <td>2</td>\n",
       "      <td>0.008461</td>\n",
       "      <td>0</td>\n",
       "      <td>사회</td>\n",
       "      <td>IT과학</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>30154</th>\n",
       "      <td>ynat-v1_train_30154</td>\n",
       "      <td>구글코리아 머신러닝 챌린지 2017 개최</td>\n",
       "      <td>3</td>\n",
       "      <td>0.002102</td>\n",
       "      <td>0</td>\n",
       "      <td>문화</td>\n",
       "      <td>IT과학</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7624</th>\n",
       "      <td>ynat-v1_train_07624</td>\n",
       "      <td>英 총리 후보 메이·레드섬 EU탈퇴 협상 싸고 견해차 뚜렷</td>\n",
       "      <td>6</td>\n",
       "      <td>0.009837</td>\n",
       "      <td>4</td>\n",
       "      <td>정치</td>\n",
       "      <td>국제</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>37594</th>\n",
       "      <td>ynat-v1_train_37594</td>\n",
       "      <td>7월 분양권 거래 양극화…수도권 76% 급증·지방 36% 줄어</td>\n",
       "      <td>3</td>\n",
       "      <td>0.001852</td>\n",
       "      <td>1</td>\n",
       "      <td>문화</td>\n",
       "      <td>경제</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13797</th>\n",
       "      <td>ynat-v1_train_13797</td>\n",
       "      <td>네이버TV캐스트 네이버TV로 새 단장…모바일 편의성↑</td>\n",
       "      <td>6</td>\n",
       "      <td>0.004966</td>\n",
       "      <td>0</td>\n",
       "      <td>정치</td>\n",
       "      <td>IT과학</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>30141</th>\n",
       "      <td>ynat-v1_train_30141</td>\n",
       "      <td>가루다항공 인도네시아·호주 항공권 최대 15% 할인</td>\n",
       "      <td>6</td>\n",
       "      <td>0.001298</td>\n",
       "      <td>4</td>\n",
       "      <td>정치</td>\n",
       "      <td>국제</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>36521</th>\n",
       "      <td>ynat-v1_train_36521</td>\n",
       "      <td>혈압측정에 무선이어폰 수납까지…각양각색 스마트워치 눈길</td>\n",
       "      <td>3</td>\n",
       "      <td>0.000443</td>\n",
       "      <td>0</td>\n",
       "      <td>문화</td>\n",
       "      <td>IT과학</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9195</th>\n",
       "      <td>ynat-v1_train_09195</td>\n",
       "      <td>미원상사 1주당 1천원 분기배당</td>\n",
       "      <td>2</td>\n",
       "      <td>0.008016</td>\n",
       "      <td>1</td>\n",
       "      <td>사회</td>\n",
       "      <td>경제</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>26949</th>\n",
       "      <td>ynat-v1_train_26949</td>\n",
       "      <td>판문점 선언 함께 걷는 남북정상</td>\n",
       "      <td>5</td>\n",
       "      <td>0.000612</td>\n",
       "      <td>6</td>\n",
       "      <td>스포츠</td>\n",
       "      <td>정치</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>21106</th>\n",
       "      <td>ynat-v1_train_21106</td>\n",
       "      <td>애플 뮤직에 성인용 콘텐츠 추가…5천만곡으로 확대</td>\n",
       "      <td>2</td>\n",
       "      <td>0.006954</td>\n",
       "      <td>0</td>\n",
       "      <td>사회</td>\n",
       "      <td>IT과학</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                        ID                                text  target   \n",
       "5480   ynat-v1_train_05480       KT·SKT 5G 통신 국제 표준 규격 개발 주도종합       2  \\\n",
       "30154  ynat-v1_train_30154              구글코리아 머신러닝 챌린지 2017 개최       3   \n",
       "7624   ynat-v1_train_07624    英 총리 후보 메이·레드섬 EU탈퇴 협상 싸고 견해차 뚜렷       6   \n",
       "37594  ynat-v1_train_37594  7월 분양권 거래 양극화…수도권 76% 급증·지방 36% 줄어       3   \n",
       "13797  ynat-v1_train_13797       네이버TV캐스트 네이버TV로 새 단장…모바일 편의성↑       6   \n",
       "30141  ynat-v1_train_30141        가루다항공 인도네시아·호주 항공권 최대 15% 할인       6   \n",
       "36521  ynat-v1_train_36521      혈압측정에 무선이어폰 수납까지…각양각색 스마트워치 눈길       3   \n",
       "9195   ynat-v1_train_09195                   미원상사 1주당 1천원 분기배당       2   \n",
       "26949  ynat-v1_train_26949                   판문점 선언 함께 걷는 남북정상       5   \n",
       "21106  ynat-v1_train_21106         애플 뮤직에 성인용 콘텐츠 추가…5천만곡으로 확대       2   \n",
       "\n",
       "       label_quality  predicted_label text_target text_predicted_label  \n",
       "5480        0.008461                0          사회                 IT과학  \n",
       "30154       0.002102                0          문화                 IT과학  \n",
       "7624        0.009837                4          정치                   국제  \n",
       "37594       0.001852                1          문화                   경제  \n",
       "13797       0.004966                0          정치                 IT과학  \n",
       "30141       0.001298                4          정치                   국제  \n",
       "36521       0.000443                0          문화                 IT과학  \n",
       "9195        0.008016                1          사회                   경제  \n",
       "26949       0.000612                6         스포츠                   정치  \n",
       "21106       0.006954                0          사회                 IT과학  "
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df = df_train.copy()\n",
    "\n",
    "dictionary = {\n",
    "    0: 'IT과학',\n",
    "    1: '경제',\n",
    "    2: '사회',\n",
    "    3: '문화',\n",
    "    4: '국제',\n",
    "    5: '스포츠',\n",
    "    6: '정치'\n",
    "}\n",
    "\n",
    "df['text_target'] = df['target'].replace(dictionary)\n",
    "df['text_predicted_label'] = df['predicted_label'].replace(dictionary)\n",
    "df.drop(['url', 'date'], axis=1, inplace=True)\n",
    "df[df['label_quality'] <= 0.01].sample(10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>ID</th>\n",
       "      <th>text</th>\n",
       "      <th>target</th>\n",
       "      <th>label_quality</th>\n",
       "      <th>predicted_label</th>\n",
       "      <th>text_target</th>\n",
       "      <th>text_predicted_label</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>42</th>\n",
       "      <td>ynat-v1_train_21763</td>\n",
       "      <td>올림픽 평창 계촌5리 작은 마을서 지구촌 화합 파티</td>\n",
       "      <td>5</td>\n",
       "      <td>0.004693</td>\n",
       "      <td>5</td>\n",
       "      <td>문화</td>\n",
       "      <td>스포츠</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>92</th>\n",
       "      <td>ynat-v1_train_10074</td>\n",
       "      <td>친박계 김무성 권력자 발언에 발끈…확전은 자제</td>\n",
       "      <td>6</td>\n",
       "      <td>0.000762</td>\n",
       "      <td>6</td>\n",
       "      <td>IT과학</td>\n",
       "      <td>정치</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>97</th>\n",
       "      <td>ynat-v1_train_34479</td>\n",
       "      <td>한수원 안전 공익광고로 서울영상광고제 은상 수상</td>\n",
       "      <td>2</td>\n",
       "      <td>0.006309</td>\n",
       "      <td>2</td>\n",
       "      <td>문화</td>\n",
       "      <td>사회</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>289</th>\n",
       "      <td>ynat-v1_train_00354</td>\n",
       "      <td>인공지능에서 구글과 경쟁하려면 데이터 확보 중요</td>\n",
       "      <td>0</td>\n",
       "      <td>0.001035</td>\n",
       "      <td>0</td>\n",
       "      <td>국제</td>\n",
       "      <td>IT과학</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>381</th>\n",
       "      <td>ynat-v1_train_26552</td>\n",
       "      <td>단독 멈춰선 롯데…수조원대 면세점·호텔 인수도 무산</td>\n",
       "      <td>1</td>\n",
       "      <td>0.002261</td>\n",
       "      <td>1</td>\n",
       "      <td>IT과학</td>\n",
       "      <td>경제</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13569</th>\n",
       "      <td>ynat-v1_train_24010</td>\n",
       "      <td>백악관 IS 시리아에서 100% 제거됐다</td>\n",
       "      <td>4</td>\n",
       "      <td>0.000833</td>\n",
       "      <td>4</td>\n",
       "      <td>경제</td>\n",
       "      <td>국제</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13572</th>\n",
       "      <td>ynat-v1_train_27428</td>\n",
       "      <td>연구성과로 창업을…과기부 실험실 일자리 토크콘서트</td>\n",
       "      <td>0</td>\n",
       "      <td>0.004482</td>\n",
       "      <td>0</td>\n",
       "      <td>문화</td>\n",
       "      <td>IT과학</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13618</th>\n",
       "      <td>ynat-v1_train_06491</td>\n",
       "      <td>靑 우병우 수석 휴가복귀 후 정상근무</td>\n",
       "      <td>6</td>\n",
       "      <td>0.001107</td>\n",
       "      <td>6</td>\n",
       "      <td>스포츠</td>\n",
       "      <td>정치</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13642</th>\n",
       "      <td>ynat-v1_train_02464</td>\n",
       "      <td>그리스 조만간 10년물 국고채 발행…구제금융 이후 처음</td>\n",
       "      <td>4</td>\n",
       "      <td>0.000253</td>\n",
       "      <td>4</td>\n",
       "      <td>사회</td>\n",
       "      <td>국제</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13660</th>\n",
       "      <td>ynat-v1_train_36252</td>\n",
       "      <td>생방송 앱 단속 철저히 해라 中 규제당국 애플 소환 예정</td>\n",
       "      <td>4</td>\n",
       "      <td>0.009003</td>\n",
       "      <td>4</td>\n",
       "      <td>IT과학</td>\n",
       "      <td>국제</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>459 rows × 7 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                        ID                             text  target   \n",
       "42     ynat-v1_train_21763     올림픽 평창 계촌5리 작은 마을서 지구촌 화합 파티       5  \\\n",
       "92     ynat-v1_train_10074        친박계 김무성 권력자 발언에 발끈…확전은 자제       6   \n",
       "97     ynat-v1_train_34479       한수원 안전 공익광고로 서울영상광고제 은상 수상       2   \n",
       "289    ynat-v1_train_00354       인공지능에서 구글과 경쟁하려면 데이터 확보 중요       0   \n",
       "381    ynat-v1_train_26552     단독 멈춰선 롯데…수조원대 면세점·호텔 인수도 무산       1   \n",
       "...                    ...                              ...     ...   \n",
       "13569  ynat-v1_train_24010           백악관 IS 시리아에서 100% 제거됐다       4   \n",
       "13572  ynat-v1_train_27428      연구성과로 창업을…과기부 실험실 일자리 토크콘서트       0   \n",
       "13618  ynat-v1_train_06491             靑 우병우 수석 휴가복귀 후 정상근무       6   \n",
       "13642  ynat-v1_train_02464   그리스 조만간 10년물 국고채 발행…구제금융 이후 처음       4   \n",
       "13660  ynat-v1_train_36252  생방송 앱 단속 철저히 해라 中 규제당국 애플 소환 예정       4   \n",
       "\n",
       "       label_quality  predicted_label text_target text_predicted_label  \n",
       "42          0.004693                5          문화                  스포츠  \n",
       "92          0.000762                6        IT과학                   정치  \n",
       "97          0.006309                2          문화                   사회  \n",
       "289         0.001035                0          국제                 IT과학  \n",
       "381         0.002261                1        IT과학                   경제  \n",
       "...              ...              ...         ...                  ...  \n",
       "13569       0.000833                4          경제                   국제  \n",
       "13572       0.004482                0          문화                 IT과학  \n",
       "13618       0.001107                6         스포츠                   정치  \n",
       "13642       0.000253                4          사회                   국제  \n",
       "13660       0.009003                4        IT과학                   국제  \n",
       "\n",
       "[459 rows x 7 columns]"
      ]
     },
     "execution_count": 30,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df = df_valid.copy()\n",
    "\n",
    "dictionary = {\n",
    "    0: 'IT과학',\n",
    "    1: '경제',\n",
    "    2: '사회',\n",
    "    3: '문화',\n",
    "    4: '국제',\n",
    "    5: '스포츠',\n",
    "    6: '정치'\n",
    "}\n",
    "\n",
    "df['text_target'] = df['target'].replace(dictionary)\n",
    "df['text_predicted_label'] = df['predicted_label'].replace(dictionary)\n",
    "df.drop(['url', 'date'], axis=1, inplace=True)\n",
    "\n",
    "df[df['label_quality'] <= 0.01]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_train['target'] = df_train.apply(lambda row: row['predicted_label'] if row['label_quality'] <= 0.01 else row['target'], axis=1)\n",
    "df_valid['target'] = df_valid.apply(lambda row: row['predicted_label'] if row['label_quality'] <= 0.01 else row['target'], axis=1)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
